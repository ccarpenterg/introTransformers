Introduction to Transformers
============================

### 1a) Introduction to Attention and Transformers

## References

**Lectures and Presentations**

[1] Machine Translation, Seq2Seq and Attention ([slides](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/slides/cs224n-2019-lecture08-nmt.pdf)) ([video](https://youtu.be/XXtpJxZBa2c)). CS224n: NLP with Deep Learning (2019), Stanford University

[2] Modeling contexts of use: Contextual Representations and Pretraining ([slides](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/slides/cs224n-2019-lecture13-contextual-representations.pdf)) ([video](https://youtu.be/S-CspeZ8FHc)). CS224n: NLP with Deep Learning (2019), Stanford University

**Papers**

[3] Attention is All You Need, [Vaswani 2017](https://arxiv.org/pdf/1706.03762.pdf).
